{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "# 激活函数\n",
    "class ActivationBase(ABC):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "    def __call__(self, z):\n",
    "        if z.dim == 1:\n",
    "            z = z.reshape(1, -1)\n",
    "        return self.forward(z)\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(self, z):\n",
    "        \"\"\"前向传播，通过激活函数得到 a\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abstractmethod\n",
    "    def grad(self, x, **kwargs):\n",
    "        \"\"\"反向传播，获得梯度\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class ReLU(ActivationBase):\n",
    "    \"\"\"整流线性单元\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def __str__(self):\n",
    "        return 'ReLU'\n",
    "\n",
    "    def forward(self, z):\n",
    "        return np.clip(z, 0, np.inf)\n",
    "\n",
    "    def grad(self, x, **kwargs):\n",
    "        return (x > 0).astype(int)\n",
    "\n",
    "\n",
    "class Sigmoid(ActivationBase):\n",
    "    \"\"\"sigmoid 激活函数\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def __str__(self):\n",
    "        return 'Sigmoid'\n",
    "\n",
    "    def forward(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def grad(self, x, **kwargs):\n",
    "        return self.forward(x) * (1 - self.forward(x))\n",
    "\n",
    "\n",
    "class Tanh(ActivationBase):\n",
    "    \"\"\"双曲正弦函数\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def __str__(self):\n",
    "        return 'Tanh'\n",
    "\n",
    "    def forward(self, z):\n",
    "        return np.tanh(z)\n",
    "\n",
    "    def grad(self, x, **kwargs):\n",
    "        return 1 - np.tanh(x) ** 2\n",
    "\n",
    "\n",
    "class Affine(ActivationBase):\n",
    "    \"\"\"affine 激活函数，即仿射变换。输出 slope*z + intercept。当 slope=1 且 intercept=0 表示不做变换\"\"\"\n",
    "    def __init__(self, slope=1, intercept=0):\n",
    "        self.slope = slope\n",
    "        self.intercept = intercept\n",
    "        super().__init__()\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'Affine(slope={self.slope}, intercept={self.intercept})'\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.slope * z + self.intercept\n",
    "\n",
    "    def grad(self, x, **kwargs):\n",
    "        return  self.slope * np.ones_like(x)\n",
    "\n",
    "\n",
    "class ActivationInitializer:\n",
    "    def __init__(self, acti_name='sigmoid'):\n",
    "        self.acti_name = acti_name\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        if self.acti_name.lower() == 'sigmoid':\n",
    "            acti_fn = Sigmoid()\n",
    "        elif self.acti_name.lower() == 'relu':\n",
    "            acti_fn = ReLU()\n",
    "        elif 'affine' in self.acti_name.lower():\n",
    "            r = r'affine\\(slope(.*), intercept=(.*)\\)'\n",
    "            slope, intercept = re.match(r, self.acti_name.lower()).groups()\n",
    "            acti_fn = Affine(float(slope), float(intercept))\n",
    "        return acti_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# 输出单元\n",
    "def sigmoid(x):\n",
    "    return  1 / (1 + np.exp(-x))\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
    "    return e_x / e_x.sum(axis=-1, keepdims=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 定义权重初始化方法\n",
    "class std_normal:\n",
    "    \"\"\"标准正态初始化\"\"\"\n",
    "    def __init__(self, gain=0.01):\n",
    "        self.gain = gain\n",
    "\n",
    "    def __call__(self, weight_shape):\n",
    "        return self.gain * np.random.randn(*weight_shape)\n",
    "\n",
    "\n",
    "class he_uniform:\n",
    "    \"\"\"He 初始化，通过 Uniform(-b, b) 初始化权重矩阵 W，这里的 b=sqrt(6 / n_in)\"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, weight_shape):\n",
    "        n_in, n_out = weight_shape\n",
    "        b = np.sqrt(6 / n_in)\n",
    "        return np.random.uniform(-b, b, size=weight_shape)\n",
    "\n",
    "\n",
    "class WeightInitializer:\n",
    "    def __init__(self, mode='he_uniform'):\n",
    "        self.mode = mode\n",
    "        r = r'([a-zA-z]*)=([^,]*)'\n",
    "        mode_str = self.mode.lower()\n",
    "        kwargs = dict([(i, eval(j)) for (i, j) in re.findall(r, mode_str)])\n",
    "\n",
    "        if 'std_normal' in mode_str:\n",
    "            self.init_fn = std_normal(**kwargs)\n",
    "        elif 'he_uniform' in mode_str:\n",
    "            self.init_fn = he_uniform(**kwargs)\n",
    "\n",
    "    def __call__(self, weight_shape):\n",
    "        W = self.init_fn(weight_shape)\n",
    "        return W"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 定义优化 - sgd\n",
    "class OptimizerBase(ABC):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, params, params_grad, params_name):\n",
    "        \"\"\"\n",
    "        参数说明\n",
    "        :param params: 待更新参数，如权重矩阵 w；\n",
    "        :param params_grad: 待更新参数的梯度；\n",
    "        :param params_name: 待更新参数的名称\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return self.update(params, params_grad, params_name)\n",
    "\n",
    "    @abstractmethod\n",
    "    def update(self, params, params_grad, params_name):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class SGD(OptimizerBase):\n",
    "    \"\"\"sgd 优化方法\"\"\"\n",
    "    def __init__(self, lr=0.01):\n",
    "        super().__init__()\n",
    "        self.lr= lr\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'SGD(lr={self.hyperparams[\"lr\"]})'\n",
    "\n",
    "    def update(self, params, params_grad, params_name):\n",
    "        update_value = self.lr * params_grad\n",
    "        return params - update_value\n",
    "\n",
    "    @property\n",
    "    def hyperparams(self):\n",
    "        return {\n",
    "            'op': 'SGD',\n",
    "            'lr': self.lr\n",
    "        }\n",
    "\n",
    "\n",
    "class OptimizerInitializer(ABC):\n",
    "    def __init__(self, opti_name=\"sgd\"):\n",
    "        self.opti_name = opti_name\n",
    "\n",
    "    def __call__(self):\n",
    "        r = r\"([a-zA-Z]*)=([^,)]*)\"\n",
    "        opti_str = self.opti_name.lower()\n",
    "        kwargs = dict([(i, eval(j)) for (i, j) in re.findall(r, opti_str)])\n",
    "\n",
    "        if \"sgd\" in opti_str:\n",
    "            optimizer = SGD(**kwargs)\n",
    "\n",
    "        return optimizer"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
